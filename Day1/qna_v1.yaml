version: 3
domain: Openshift Baremetal
created_by: willsparker
document_outline: |
  Red Hat OpenShift Container Platform v4.18 Bare Metal Cluster Installation Preparation.
seed_examples:
  - context: |
      ## CHAPTER 1. PREPARING FOR BARE METAL CLUSTER INSTALLATION
      ## 1.1. PREREQUISITES
      - You reviewed details about the OpenShift Container Platform installation and update processes.
      - You have read the documentation on selecting a cluster installation method and preparing it for users.

      ## 1.2. PLANNING A BARE METAL CLUSTER FOR OPENSHIFT VIRTUALIZATION
      If you will use OpenShift Virtualization, it is important to be aware of several requirements before you install your bare metal cluster.
      - If you want to use live migration features, you must have multiple worker nodes at the time of cluster installation . This is because live migration requires the cluster-level high availability (HA) flag to be set to true. The HA flag is set when a cluster is installed and cannot be changed afterwards. If there are fewer than two worker nodes defined when you install your cluster, the HA flag is set to false for the life of the cluster.
      You can install OpenShift Virtualization on a single-node cluster, but single-node OpenShift does not support high availability.
      - Live migration requires shared storage. Storage for OpenShift Virtualization must support and use the ReadWriteMany (RWX) access mode.
      - If you plan to use Single Root I/O Virtualization (SR-IOV), ensure that your network interface controllers (NICs) are supported by OpenShift Container Platform.
      ## Additional resources
      - Getting started with OpenShift Virtualization
      - Preparing your cluster for OpenShift Virtualization
      - About Single Root I/O Virtualization (SR-IOV) hardware networks
      - Connecting a virtual machine to an SR-IOV networkx
    questions_and_answers:
      - question: |
          Can Openshift Virtualization be installed on a single-node cluster?
        answer: |
          Yes, but it does not support high availability.
      - question: |
          What kind of storage does live migration require?
        answer: |
          Live migration requires shared storage. It must also support the ReadWriteMany (RWX) access mode.
      - question: |
          What do I need to be aware of when installing Openshift Virtualization on a bare metal cluster?
        answer: |
          You will have to have multiple worker nodes at the cluster installation time. This is because the cluster-level high availability flag (HA) flag must be set to true, to use live migration. 

  - context: |
      ## 1.3. NIC PARTITIONING FOR SR-IOV DEVICES

      OpenShift Container Platform can be deployed on a server with a dual port network interface card (NIC). You can partition a single, high-speed dual port NIC into multiple virtual functions (VFs) and enable SR-IOV.

      This feature supports the use of bonds for high availability with the Link Aggregation Control Protocol (LACP).

      Only one LACP can be declared by physical NIC.

      An OpenShift Container Platform cluster can be deployed on a bond interface with 2 VFs on 2 physical functions (PFs) using the following methods:

      - Agent-based installer

      The minimum required version of nmstate is:
        - 1.4.2-4 for RHEL 8 versions
        - 2.2.7 for RHEL 9 versions
      - Installer-provisioned infrastructure installation
      - User-provisioned infrastructure installation

      - Example: Bonds and SR-IOV dual-nic node network configuration
      - Optional: Configuring host network interfaces for dual port NIC
      - Bonding multiple SR-IOV network interfaces to a dual port NIC interface
    questions_and_answers:
      - question: |
          What is the minimum required version of nmstate, for RHEL9?
        answer: |
          nmstate v2.2.7
      - question: |
          How many LACP can be declared by physical NIC?
        answer: |
          Just one.
      - question: |
          What feature supports the use of bonds for HA with the LACP?
        answer: |
          SR-IOV with a single high-speed dual port NIC into multiple virtual functions.

  - context: |
      You can install a cluster on bare metal infrastructure that is provisioned by the OpenShift Container Platform installation program, by using the following method:
        - Installing an installer-provisioned cluster on bare metal : You can install OpenShift Container Platform on bare metal by using installer provisioning.
      You can install a cluster on bare metal infrastructure that you provision, by using one of the following methods:

        - Installing a user-provisioned cluster on bare metal : You can install OpenShift Container Platform on bare metal infrastructure that you provision. For a cluster that contains user-provisioned infrastructure, you must deploy all of the required machines.
        - Installing a user-provisioned bare metal cluster with network customizations : You can install a bare metal cluster on user-provisioned infrastructure with network customizations. By customizing your network configuration, your cluster can coexist with existing IP address allocations in your environment and integrate with existing MTU and VXLAN configurations. Most of the network customizations must be applied at the installation stage.
        - Installing a user-provisioned bare metal cluster on a restricted network : You can install a user-provisioned bare metal cluster on a restricted or disconnected network by using a mirror registry. You can also use this installation method to ensure that your clusters only use container images that satisfy your organizational controls on external content.
    questions_and_answers:
      - question: |
          What distinguishes installer-provisioned from user-provisioned OpenShift installations on bare metal?
        answer: |
          Installer-provisioned installations let OpenShift handle the infrastructure setup, while user-provisioned installations require the user to manually deploy all machines. The former is more automated; the latter offers more control and flexibility.
      - question: |
          When would you use a user-provisioned bare metal cluster with network customizations?
        answer: |
          This method is used when the cluster must align with existing IP allocations, MTU, or VXLAN settings. Customizing the network during installation ensures compatibility with the organization's current infrastructure.
      - question: |
          How does installing on a restricted network support compliance?
        answer: |
          It enhances compliance by using a local mirror registry, ensuring the cluster only accesses vetted container images, which helps meet organizational or regulatory security requirements.

  - context: |
      ## 1.4. HARDWARE REQUIREMENTS FOR BARE METAL NODES
      When planning your hardware layout for an OpenShift Container Platform cluster on bare metal, ensure that each node meets the recommended CPU, memory, and storage resources.
      - For control plane (master) nodes:
        * A minimum of 4 CPU cores and 16 GB of RAM per node is recommended.
        * Provide at least 120 GB of disk space for the root file system.
      - For worker nodes:
        * CPU and memory requirements vary based on the workloads and the installed Operators.
        * Plan for sufficient storage to support the workloads running on these nodes.
      Additionally, each node must have network connectivity to the cluster network, run a supported Red Hat Enterprise Linux 8 or 9 base OS, and have hardware that supports virtualization if you plan to use features such as OpenShift Virtualization.
    questions_and_answers:
      - question: |
          What are the recommended system resources for a control plane node on bare metal?
        answer: |
          Each control plane node should have at least 4 CPU cores, 16 GB of RAM, and 120 GB of disk space for the root file system.
      - question: |
          Why do worker node resource requirements vary?
        answer: |
          They depend on the workloads, installed Operators, and overall cluster configuration. Different applications can demand different amounts of CPU, memory, and storage.
      - question: |
          Which operating system versions are supported for bare metal nodes?
        answer: |
          Red Hat Enterprise Linux 8 or 9 is recommended for bare metal nodes.

  - context: |
      ## 1.5. ADDING ADDITIONAL WORKER NODES TO A BARE METAL CLUSTER
      After installing an OpenShift Container Platform cluster on bare metal, you might need to scale out by adding more worker nodes. 
      - Confirm that the new node meets hardware requirements (CPU, RAM, disk).
      - Register the node with Red Hat Enterprise Linux subscription if needed.
      - Attach the node to the same network as the cluster, ensuring DNS and DHCP are properly configured.
      - Use the OpenShift CLI (oc) or the web console to add and configure the node.
      - Label and taint the node if you want to reserve it for specific workloads or isolate it from other tasks.
      - Monitor cluster logs and resource usage during the addition process to ensure a seamless scale-out.
    questions_and_answers:
      - question: |
          What steps are involved in adding a new worker node to an existing bare metal cluster?
        answer: |
          You must ensure hardware requirements are met, attach the node to the clusterâ€™s network, register the node if required, then use the OpenShift CLI or web console to join it to the cluster. Finally, label or taint the node if specific workloads or isolation is needed.
      - question: |
          Why would you label or taint a newly added worker node?
        answer: |
          Labeling or tainting helps reserve the node for specific workloads, isolating them from the rest of the cluster and enabling finer control over where workloads are scheduled.
      - question: |
          Which tools can be used to add a worker node to the cluster?
        answer: |
          You can use the OpenShift CLI (oc) or the OpenShift web console to add and manage new worker nodes.
document:
  repo: 'https://github.com/rflorenc/etx-labs.git'
  commit: '194272c6a0a242e4d27a2481256491373c12d440'
  patterns:
    - './knowledge.md'
